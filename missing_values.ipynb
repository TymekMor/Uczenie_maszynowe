{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19367a9f-024d-40fa-9ede-c2b5ff99ccc0",
   "metadata": {},
   "source": [
    "# Lab 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cebac67-725c-434e-a7a8-835ce89c9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arff\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd1cbe39-4262-4251-9887-47a7b4fe37e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('dane.arff', 'r') as f:\n",
    "    data = arff.load(f)\n",
    "attributes = [attr[0] for attr in data['attributes']]\n",
    "data_rows = data['data']\n",
    "df = pd.DataFrame(data_rows, columns=attributes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce21c91a-895e-4e26-8aa3-fdba0d7ed9cc",
   "metadata": {},
   "source": [
    "Dokonaj wstępnej inspekcji pierwszych 20 wierszy. Co widzisz? Jaka jest liczba (features) cech w zbiorze?\n",
    " - features: 14\n",
    " - brakuje danych w features: age,cabin,embarked,boat,body,home.dest\n",
    " - przy czym boat cabin i body mają ponad 50% brakujących danych, body aż 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb42cab7-92b8-4de4-bf18-5a735cc7eed1",
   "metadata": {},
   "source": [
    "VARIABLE DESCRIPTIONS\n",
    "- Pclass Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "- survival Survival (0 = No; 1 = Yes)\n",
    "- name Name\n",
    "- sex Sex\n",
    "- age Age\n",
    "- sibsp Number of Siblings/Spouses Aboard\n",
    "- parch Number of Parents/Children Aboard\n",
    "- ticket Ticket Number\n",
    "- fare Passenger Fare (British pound)\n",
    "- cabin Cabin\n",
    "- embarked Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "- boat Lifeboat\n",
    "- body Body Identification Number\n",
    "- home.dest Home/Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae2439be-e7a8-430d-8afe-fc912884caff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>cabinNull</th>\n",
       "      <th>boatNull</th>\n",
       "      <th>home.destNull</th>\n",
       "      <th>ageNull</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Anderson, Mr. Harry</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19952</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>E12</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrews, Miss. Kornelia Theodosia</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13502</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>D7</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hudson, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Andrews, Mr. Thomas Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>A36</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belfast, NI</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Appleton, Mrs. Edward Dale (Charlotte Lamson)</td>\n",
       "      <td>female</td>\n",
       "      <td>53.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11769</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>C101</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bayside, Queens, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Artagaveytia, Mr. Ramon</td>\n",
       "      <td>male</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17609</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Montevideo, Uruguay</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Astor, Col. John Jacob</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>C62 C64</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>124.0</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Astor, Mrs. John Jacob (Madeleine Talmadge Force)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>C62 C64</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Aubart, Mme. Leontine Pauline</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17477</td>\n",
       "      <td>69.3000</td>\n",
       "      <td>B35</td>\n",
       "      <td>C</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Barber, Miss. Ellen 'Nellie'</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19877</td>\n",
       "      <td>78.8500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Barkworth, Mr. Algernon Henry Wilson</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27042</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>A23</td>\n",
       "      <td>S</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hessle, Yorks</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Baumann, Mr. John D</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17318</td>\n",
       "      <td>25.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Baxter, Mr. Quigg Edmond</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17558</td>\n",
       "      <td>247.5208</td>\n",
       "      <td>B58 B60</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Baxter, Mrs. James (Helene DeLaudeniere Chaput)</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17558</td>\n",
       "      <td>247.5208</td>\n",
       "      <td>B58 B60</td>\n",
       "      <td>C</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bazzani, Miss. Albina</td>\n",
       "      <td>female</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11813</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>D15</td>\n",
       "      <td>C</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Beattie, Mr. Thomson</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13050</td>\n",
       "      <td>75.2417</td>\n",
       "      <td>C6</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winnipeg, MN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pclass survived                                               name  \\\n",
       "0      1.0        1                      Allen, Miss. Elisabeth Walton   \n",
       "1      1.0        1                     Allison, Master. Hudson Trevor   \n",
       "2      1.0        0                       Allison, Miss. Helen Loraine   \n",
       "3      1.0        0               Allison, Mr. Hudson Joshua Creighton   \n",
       "4      1.0        0    Allison, Mrs. Hudson J C (Bessie Waldo Daniels)   \n",
       "5      1.0        1                                Anderson, Mr. Harry   \n",
       "6      1.0        1                  Andrews, Miss. Kornelia Theodosia   \n",
       "7      1.0        0                             Andrews, Mr. Thomas Jr   \n",
       "8      1.0        1      Appleton, Mrs. Edward Dale (Charlotte Lamson)   \n",
       "9      1.0        0                            Artagaveytia, Mr. Ramon   \n",
       "10     1.0        0                             Astor, Col. John Jacob   \n",
       "11     1.0        1  Astor, Mrs. John Jacob (Madeleine Talmadge Force)   \n",
       "12     1.0        1                      Aubart, Mme. Leontine Pauline   \n",
       "13     1.0        1                       Barber, Miss. Ellen 'Nellie'   \n",
       "14     1.0        1               Barkworth, Mr. Algernon Henry Wilson   \n",
       "15     1.0        0                                Baumann, Mr. John D   \n",
       "16     1.0        0                           Baxter, Mr. Quigg Edmond   \n",
       "17     1.0        1    Baxter, Mrs. James (Helene DeLaudeniere Chaput)   \n",
       "18     1.0        1                              Bazzani, Miss. Albina   \n",
       "19     1.0        0                               Beattie, Mr. Thomson   \n",
       "\n",
       "       sex      age  sibsp  parch    ticket      fare    cabin embarked  boat  \\\n",
       "0   female  29.0000    0.0    0.0     24160  211.3375       B5        S     2   \n",
       "1     male   0.9167    1.0    2.0    113781  151.5500  C22 C26        S    11   \n",
       "2   female   2.0000    1.0    2.0    113781  151.5500  C22 C26        S  None   \n",
       "3     male  30.0000    1.0    2.0    113781  151.5500  C22 C26        S  None   \n",
       "4   female  25.0000    1.0    2.0    113781  151.5500  C22 C26        S  None   \n",
       "5     male  48.0000    0.0    0.0     19952   26.5500      E12        S     3   \n",
       "6   female  63.0000    1.0    0.0     13502   77.9583       D7        S    10   \n",
       "7     male  39.0000    0.0    0.0    112050    0.0000      A36        S  None   \n",
       "8   female  53.0000    2.0    0.0     11769   51.4792     C101        S     D   \n",
       "9     male  71.0000    0.0    0.0  PC 17609   49.5042     None        C  None   \n",
       "10    male  47.0000    1.0    0.0  PC 17757  227.5250  C62 C64        C  None   \n",
       "11  female  18.0000    1.0    0.0  PC 17757  227.5250  C62 C64        C     4   \n",
       "12  female  24.0000    0.0    0.0  PC 17477   69.3000      B35        C     9   \n",
       "13  female  26.0000    0.0    0.0     19877   78.8500     None        S     6   \n",
       "14    male  80.0000    0.0    0.0     27042   30.0000      A23        S     B   \n",
       "15    male      NaN    0.0    0.0  PC 17318   25.9250     None        S  None   \n",
       "16    male  24.0000    0.0    1.0  PC 17558  247.5208  B58 B60        C  None   \n",
       "17  female  50.0000    0.0    1.0  PC 17558  247.5208  B58 B60        C     6   \n",
       "18  female  32.0000    0.0    0.0     11813   76.2917      D15        C     8   \n",
       "19    male  36.0000    0.0    0.0     13050   75.2417       C6        C     A   \n",
       "\n",
       "     body                        home.dest  cabinNull  boatNull  \\\n",
       "0     NaN                     St Louis, MO          0         0   \n",
       "1     NaN  Montreal, PQ / Chesterville, ON          0         0   \n",
       "2     NaN  Montreal, PQ / Chesterville, ON          0         1   \n",
       "3   135.0  Montreal, PQ / Chesterville, ON          0         1   \n",
       "4     NaN  Montreal, PQ / Chesterville, ON          0         1   \n",
       "5     NaN                     New York, NY          0         0   \n",
       "6     NaN                       Hudson, NY          0         0   \n",
       "7     NaN                      Belfast, NI          0         1   \n",
       "8     NaN              Bayside, Queens, NY          0         0   \n",
       "9    22.0              Montevideo, Uruguay          1         1   \n",
       "10  124.0                     New York, NY          0         1   \n",
       "11    NaN                     New York, NY          0         0   \n",
       "12    NaN                    Paris, France          0         0   \n",
       "13    NaN                             None          1         0   \n",
       "14    NaN                    Hessle, Yorks          0         0   \n",
       "15    NaN                     New York, NY          1         1   \n",
       "16    NaN                     Montreal, PQ          0         1   \n",
       "17    NaN                     Montreal, PQ          0         0   \n",
       "18    NaN                             None          0         0   \n",
       "19    NaN                     Winnipeg, MN          0         0   \n",
       "\n",
       "    home.destNull  ageNull  \n",
       "0               0        0  \n",
       "1               0        0  \n",
       "2               0        0  \n",
       "3               0        0  \n",
       "4               0        0  \n",
       "5               0        0  \n",
       "6               0        0  \n",
       "7               0        0  \n",
       "8               0        0  \n",
       "9               0        0  \n",
       "10              0        0  \n",
       "11              0        0  \n",
       "12              0        0  \n",
       "13              1        0  \n",
       "14              0        0  \n",
       "15              0        1  \n",
       "16              0        0  \n",
       "17              0        0  \n",
       "18              1        0  \n",
       "19              0        0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6939ca4-35c8-4a72-a665-1ee817ed164a",
   "metadata": {},
   "source": [
    "2.     Sprawdź, ile jest wartości brakujących używając funkcji pd.isnull().sum() oraz pd.isnull().mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61824fbe-c24a-4bb0-a176-b833ad376f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wymiary: rows: 1309 features: 14\n",
      "pclass          0\n",
      "survived        0\n",
      "name            0\n",
      "sex             0\n",
      "age           263\n",
      "sibsp           0\n",
      "parch           0\n",
      "ticket          0\n",
      "fare            1\n",
      "cabin        1014\n",
      "embarked        2\n",
      "boat          823\n",
      "body         1188\n",
      "home.dest     564\n",
      "dtype: int64\n",
      "pclass       0.000000\n",
      "survived     0.000000\n",
      "name         0.000000\n",
      "sex          0.000000\n",
      "age          0.200917\n",
      "sibsp        0.000000\n",
      "parch        0.000000\n",
      "ticket       0.000000\n",
      "fare         0.000764\n",
      "cabin        0.774637\n",
      "embarked     0.001528\n",
      "boat         0.628724\n",
      "body         0.907563\n",
      "home.dest    0.430863\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Wymiary: rows:', df.shape[0],'features:', df.shape[1])\n",
    "print(df.isnull().sum())\n",
    "print(df.isnull().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f882410a-eb5b-404c-9fac-0e80ba13b874",
   "metadata": {},
   "source": [
    "Zbadajmy feature: body, ponieważ tam brakuje najwięcej danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34779469-fdb1-430e-882f-bc1e76eb4812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilość osób które nie przeżyły: 809\n",
      "Ilość znalezionych ciał: 121\n",
      "Ilość NIE znalezionych ciał: 688\n",
      "Ilość wartości NaN: 1188\n",
      "Suma NIE znalezionych ciał i osób które przeżyły jest równa ilości wartośći NaN w naszym zbiorze, stąd ponad 90% 'brakujących' danych\n",
      "Oznacza to, że jest to MNAR, ponieważ dla każdego survived == 1, mamy NaN\n",
      "\n",
      "W jaki sposób należy postąpić z brakującymi wartościami ?\n",
      "Można dokonać imputacji medianom lub metodami jak forward/backward fill, aczkolwiek ryzykujemy zwiększeniem bias w danych\n"
     ]
    }
   ],
   "source": [
    "non_survivors = df.groupby('survived').size()[0]\n",
    "found_bodies = df.groupby('survived')['body'].count()[0]\n",
    "not_found_bodies = non_survivors - found_bodies\n",
    "survivors_and_not_found_bodies = len(df['survived']) - found_bodies\n",
    "print('Ilość osób które nie przeżyły:',non_survivors)\n",
    "\n",
    "print('Ilość znalezionych ciał:',found_bodies)\n",
    "\n",
    "print('Ilość NIE znalezionych ciał:',not_found_bodies)\n",
    "\n",
    "print(\"Ilość wartości NaN:\", survivors_and_not_found_bodies) \n",
    "print(\"Suma NIE znalezionych ciał i osób które przeżyły jest równa ilości wartośći NaN w naszym zbiorze, stąd ponad 90% 'brakujących' danych\")\n",
    "print(\"Oznacza to, że jest to MNAR, ponieważ dla każdego survived == 1, mamy NaN\")\n",
    "print(\"\\nW jaki sposób należy postąpić z brakującymi wartościami ?\")\n",
    "print(\"Można dokonać imputacji medianom/średnią/modą lub metodami jak forward/backward fill, aczkolwiek ryzykujemy zwiększeniem bias w danych\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1a3d6-905e-472f-a4ff-5c79ded55081",
   "metadata": {},
   "source": [
    "Następnie zbadajmy feature: cabin == MAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fa2e4c7-1471-4e47-9eef-da751763b9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived  cabinNull\n",
      "0         0            102\n",
      "          1            707\n",
      "1         0            193\n",
      "          1            307\n",
      "dtype: int64\n",
      "Najwięcej danych brakuje dla osób, które nie przeżyły: 707. Co ciekawe dla osób, które przetrwały mamy 307 brakujących danych\n",
      "Może pasażerowie w ramach szoku zapomnieli, w jakich kabinach mieszkali, lub jest to część załogi, która mieszkała w niezonazkowanych kabinach\n",
      "Jest to jedynie spekulacja, więc możemy oznaczyć tą kolumną jako MAR, ponieważ brakujące dane nie mają jednostajnego rozkładu\n",
      "\n",
      "W jaki sposób należy postąpić z brakującymi wartościami ?\n",
      "Można dokonać imputacji medianom lub metodami jak forward/backward fill, aczkolwiek ryzykujemy zwiększeniem bias w danych\n"
     ]
    }
   ],
   "source": [
    "df['cabinNull'] = np.where(df['cabin'].isnull(), 1, 0)\n",
    "print(df.groupby(['survived','cabinNull']).size())\n",
    "print('Najwięcej danych brakuje dla osób, które nie przeżyły: 707. Co ciekawe dla osób, które przetrwały mamy 307 brakujących danych')\n",
    "print('Może pasażerowie w ramach szoku zapomnieli, w jakich kabinach mieszkali, lub jest to część załogi, która mieszkała w niezonazkowanych kabinach')\n",
    "print('Jest to jedynie spekulacja, więc możemy oznaczyć tą kolumną jako MAR, ponieważ brakujące dane nie mają jednostajnego rozkładu')\n",
    "print(\"\\nW jaki sposób należy postąpić z brakującymi wartościami ?\")\n",
    "print(\"Można dokonać imputacji medianom/średnią/modą lub metodami jak forward/backward fill, aczkolwiek ryzykujemy zwiększeniem bias w danych\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa2b7a-212d-406f-982d-69a29249cc27",
   "metadata": {},
   "source": [
    "Następnie zbadajmy feature: boat == MNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faba6be6-cdca-4568-9219-f0c194c99c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived  boatNull\n",
      "0         0             9\n",
      "          1           800\n",
      "1         0           477\n",
      "          1            23\n",
      "dtype: int64\n",
      "9 osób, które nie przeżyły, były na łodzi oraz 23 osoby które były na łodziach nie przeżyły\n",
      "Jak można się domyślić, wartość NaN w kolumnie: boat, oznacza, że osoba nie wylądowała na szalupie ratunkowej, ponieważ aż 800 osób które nie przetrwało, nie było na łodziach. A 477 które przetrwało było na łodziach. Więc jest tu ewidentna zależność\n",
      "Tak więc, brakujące dane w kolumnie: boat oznaczymy jako MNAR\n",
      "\n",
      "W jaki sposób należy postąpić z brakującymi wartościami ?\n",
      "Można dokonać imputacji medianom lub metodami jak forward/backward fill, aczkolwiek ryzykujemy zwiększeniem bias w danych\n"
     ]
    }
   ],
   "source": [
    "df['boatNull'] = np.where(df['boat'].isnull(), 1, 0)\n",
    "print(df.groupby(['survived','boatNull']).size())\n",
    "print(\"9 osób, które nie przeżyły, były na łodzi oraz 23 osoby które były na łodziach nie przeżyły\")\n",
    "print('Jak można się domyślić, wartość NaN w kolumnie: boat, oznacza, że osoba nie wylądowała na szalupie ratunkowej, ponieważ aż 800 osób które nie przetrwało, nie było na łodziach. A 477 które przetrwało było na łodziach. Więc jest tu ewidentna zależność')\n",
    "print('Tak więc, brakujące dane w kolumnie: boat oznaczymy jako MNAR')\n",
    "print(\"\\nW jaki sposób należy postąpić z brakującymi wartościami ?\")\n",
    "print(\"Można dokonać imputacji medianom/średnią/modą lub metodami jak forward/backward fill, aczkolwiek ryzykujemy zwiększeniem bias w danych\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4435d4f7-201b-4c0e-b1ed-90bc49892edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "female    46.198097\n",
       "male      26.154601\n",
       "Name: fare, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FUN FACT \n",
    "df.groupby('sex')[\"fare\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469e1d02-b5e1-474b-bacc-87bf3faa69fc",
   "metadata": {},
   "source": [
    "Następnie zbadajmy feature: home.dst == MAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80e42db9-2bc5-410b-9a17-74dc9e9b3aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived  home.destNull\n",
      "0         0                398\n",
      "          1                411\n",
      "1         0                347\n",
      "          1                153\n",
      "dtype: int64\n",
      "Nie dostrzegam, żadnej zależności pomiędzy survived a home.dest. Więc można sklasyfikować tą kolumnę jako MAR, nie MCAR, ponieważ dane nie są rozłożenie porówno\n",
      "\n",
      "W jaki sposób należy postąpić z brakującymi wartościami ?\n",
      "Można dokonać imputacji medianom lub metodami jak forward/backward fill, aczkolwiek ryzykujemy zwiększeniem bias w danych\n"
     ]
    }
   ],
   "source": [
    "df['home.destNull'] = np.where(df['home.dest'].isnull(), 1, 0)\n",
    "print(df.groupby(['survived','home.destNull']).size())\n",
    "print(\"Nie dostrzegam, żadnej zależności pomiędzy survived a home.dest. Więc można sklasyfikować tą kolumnę jako MAR, nie MCAR, ponieważ dane nie są rozłożenie porówno\")\n",
    "print(\"\\nW jaki sposób należy postąpić z brakującymi wartościami ?\")\n",
    "print(\"Można dokonać imputacji medianom/średnią/modą lub metodami jak forward/backward fill, aczkolwiek ryzykujemy zwiększeniem bias w danych\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b1b7a-8ef3-4f80-9bfa-52b4bd61a26b",
   "metadata": {},
   "source": [
    "Następnie zbadajmy feature: age == MNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6355272-be1a-4d22-8b58-fa3677b614d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass  ageNull\n",
      "1.0     0          284\n",
      "        1           39\n",
      "2.0     0          261\n",
      "        1           16\n",
      "3.0     0          501\n",
      "        1          208\n",
      "dtype: int64\n",
      "survived  ageNull\n",
      "0         0          619\n",
      "          1          190\n",
      "1         0          427\n",
      "          1           73\n",
      "dtype: int64\n",
      "Najwięcej brakujących danych jest dla pasażerów 3 klasy, dodatkowo jest prawie 3 razy więcej brakujących danych dla osób które nie przetrwały\n",
      "Tak więc można by uznać, że danych nie można było pozyskać na temat osób, które nie przetrwały a dla osób 3 kategorii nawet nie próbowano\n",
      "Można sklasyfikować tą kolumnę jako MNAR\n",
      "\n",
      "W jaki sposób należy postąpić z brakującymi wartościami ?\n",
      "Można dokonać imputacji medianom lub metodami jak forward/backward fill, aczkolwiek ryzykujemy zwiększeniem bias w danych\n"
     ]
    }
   ],
   "source": [
    "df['ageNull'] = np.where(df['age'].isnull(), 1, 0)\n",
    "print(df.groupby(['pclass','ageNull']).size())\n",
    "print(df.groupby(['survived','ageNull']).size())\n",
    "print(\"Najwięcej brakujących danych jest dla pasażerów 3 klasy, dodatkowo jest prawie 3 razy więcej brakujących danych dla osób które nie przetrwały\")\n",
    "print(\"Tak więc można by uznać, że danych nie można było pozyskać na temat osób, które nie przetrwały a dla osób 3 kategorii nawet nie próbowano\")\n",
    "print(\"Można sklasyfikować tą kolumnę jako MNAR\")\n",
    "print(\"\\nW jaki sposób należy postąpić z brakującymi wartościami ?\")\n",
    "print(\"Można dokonać imputacji medianom/średnią/modą lub metodami jak forward/backward fill, aczkolwiek ryzykujemy zwiększeniem bias w danych\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be658af4-ade1-4717-a8df-6cbc320db3ed",
   "metadata": {},
   "source": [
    "Następnie zbadajmy features: fare oraz embark  == MCAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0c522af-7cd1-4e0a-aab4-cf22b439575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fare        0.000764\n",
      "embarked    0.001528\n",
      "dtype: float64\n",
      "Brakujących danych w kolumnach fare i embarked, jest tak niewiele, że można je odrazu sklasyfikować jako MCAR\n",
      "\n",
      "W jaki sposób należy postąpić z brakującymi wartościami ?\n",
      "Można usunąć wiersze, gdzie brakuje danych, ponieważ nie tracimy wiele danych\n"
     ]
    }
   ],
   "source": [
    "print(df[['fare','embarked']].isnull().mean())\n",
    "print(\"Brakujących danych w kolumnach fare i embarked, jest tak niewiele, że można je odrazu sklasyfikować jako MCAR\")\n",
    "print(\"\\nW jaki sposób należy postąpić z brakującymi wartościami ?\")\n",
    "print(\"Można usunąć wiersze, gdzie brakuje danych, ponieważ nie tracimy wiele danych\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
